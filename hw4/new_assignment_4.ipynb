{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1AX38wWGMNdiJ1Yv3w8F_eeI906L3pMi8",
      "authorship_tag": "ABX9TyNwjefket2PHj1ugBP4qZEk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Colsai/DATA-690-WANG/blob/master/hw4/new_assignment_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lDhA-XQIYOP",
        "colab_type": "text"
      },
      "source": [
        "# Data Science 690: \n",
        "# Wang (Statistics and Visualization)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlQjaWQbE5lz",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 04  \n",
        "\n",
        "- Write code to open the text file \"census_cost.txt\" and read all lines into a list named \"line_list\". Print line_list.  \n",
        "\n",
        "- Extract the first two lines and put them in a different list named \"top2_list\". You will need to use them later. Print the top2_list.  \n",
        "\n",
        "- Put the rest of the lines (containing useful data elements) in a new list named \"data_list\". Print data_list.  \n",
        "\n",
        "- Extract the column \"Census Year\" from data_list and assign them to a list named year_list. Remove the \"\" from the last element \"2010\". Print the cleansed year_list.  \n",
        "\n",
        "- Extract the \"Total Population\" column from the data_list and assign them to a list named \"pop_list\". Remove the \",\" from the numbers since Python doesn't recognize them. Print the cleansed \"pop_list\".  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chFRPs1QE3yA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Write code to open the text file \"census_cost.txt\" and read all lines into a list named \"line_list\". Print line_list."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLYKak0xFDgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "41b01ac2-bb63-4f5a-be53-38bbbfdcccd2"
      },
      "source": [
        "file_name = \"/content/drive/My Drive/census_cost.txt\"\n",
        "\n",
        "with open(file_name, \"rt\") as my_file:\n",
        "    line_list = my_file.readlines()\n",
        "\n",
        "print(line_list)\n",
        "\n",
        "# second_line = df[1]\n",
        "# second_line\n",
        "\n",
        "# second_line.strip(\"\\n\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Census Year\\tTotal Population\\tCensus Cost\\tAverage Cost Per Person\\n', '1790\\t3,929,214\\t$44,377\\t1.13 cents\\n', '1800\\t5,308,483\\t$66,109\\t1.24 cents\\n', '1810\\t7,239,881\\t$178,445\\t2.46 cents\\n', '1820\\t9,633,822\\t$208,526\\t2.16 cents\\n', '1830\\t12,866,020\\t$378,545\\t2.94 cents\\n', '1840\\t17,069,458\\t$833,371\\t4.88 cents\\n', '1850\\t23,191,876\\t$1,423,351\\t6.14 cents\\n', '1860\\t31,443,321\\t$1,969,377\\t6.26 cents\\n', '1870\\t38,558,371\\t$3,421,198\\t8.87 cents\\n', '1880\\t50,155,783\\t$5,790,678\\t11.54 cents\\n', '1890\\t62,979,766\\t$11,547,127\\t18.33 cents\\n', '1900\\t76,303,387\\t$11,854,000\\t15.54 cents\\n', '1910\\t91,972,266\\t$15,968,000\\t17.07 cents\\n', '1920\\t105,710,620\\t$25,117,000\\t23.76 cents\\n', '1930\\t122,775,046\\t$40,156,000\\t32.71 cents\\n', '1940\\t131,669,275\\t$67,527,000\\t51.29 cents\\n', '1950\\t151,325,798\\t$91,462,000\\t60.44 cents\\n', '1960\\t179,323,175\\t$127,934,000\\t71.34 cents\\n', '1970\\t203,302,031\\t$247,653,000\\t$1.22\\n', '1980\\t226,542,199\\t$1,078,488,000\\t$4.76\\n', '1990\\t248,718,301\\t$2,492,830,000\\t$10.02\\n', '2000\\t281,421,906\\t$4.5 Billion\\t$15.99\\n', '2010*\\t308,745,538\\t$13 Billion\\t$42.11\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPhl65JMFN4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "838d2e2f-fc56-4ab3-c767-4eced35d7a3d"
      },
      "source": [
        "# Extract the first two lines and put them in a different list named \"top2_list\". You will need to use them later. Print the top2_list.\n",
        "top2_list = line_list[1:3]\n",
        "print(top2_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1790\\t3,929,214\\t$44,377\\t1.13 cents\\n', '1800\\t5,308,483\\t$66,109\\t1.24 cents\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7qOtMs0GqbA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "17bce660-c946-4071-fa22-e6808a6f3ce2"
      },
      "source": [
        "data_list = line_list[3:-1]\n",
        "print(data_list)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1810\\t7,239,881\\t$178,445\\t2.46 cents\\n', '1820\\t9,633,822\\t$208,526\\t2.16 cents\\n', '1830\\t12,866,020\\t$378,545\\t2.94 cents\\n', '1840\\t17,069,458\\t$833,371\\t4.88 cents\\n', '1850\\t23,191,876\\t$1,423,351\\t6.14 cents\\n', '1860\\t31,443,321\\t$1,969,377\\t6.26 cents\\n', '1870\\t38,558,371\\t$3,421,198\\t8.87 cents\\n', '1880\\t50,155,783\\t$5,790,678\\t11.54 cents\\n', '1890\\t62,979,766\\t$11,547,127\\t18.33 cents\\n', '1900\\t76,303,387\\t$11,854,000\\t15.54 cents\\n', '1910\\t91,972,266\\t$15,968,000\\t17.07 cents\\n', '1920\\t105,710,620\\t$25,117,000\\t23.76 cents\\n', '1930\\t122,775,046\\t$40,156,000\\t32.71 cents\\n', '1940\\t131,669,275\\t$67,527,000\\t51.29 cents\\n', '1950\\t151,325,798\\t$91,462,000\\t60.44 cents\\n', '1960\\t179,323,175\\t$127,934,000\\t71.34 cents\\n', '1970\\t203,302,031\\t$247,653,000\\t$1.22\\n', '1980\\t226,542,199\\t$1,078,488,000\\t$4.76\\n', '1990\\t248,718,301\\t$2,492,830,000\\t$10.02\\n', '2000\\t281,421,906\\t$4.5 Billion\\t$15.99\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS7uGGyyHXc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "fb1d8871-0e6f-46f9-d6b8-ff52a978ddef"
      },
      "source": [
        "data_list"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1810\\t7,239,881\\t$178,445\\t2.46 cents\\n',\n",
              " '1820\\t9,633,822\\t$208,526\\t2.16 cents\\n',\n",
              " '1830\\t12,866,020\\t$378,545\\t2.94 cents\\n',\n",
              " '1840\\t17,069,458\\t$833,371\\t4.88 cents\\n',\n",
              " '1850\\t23,191,876\\t$1,423,351\\t6.14 cents\\n',\n",
              " '1860\\t31,443,321\\t$1,969,377\\t6.26 cents\\n',\n",
              " '1870\\t38,558,371\\t$3,421,198\\t8.87 cents\\n',\n",
              " '1880\\t50,155,783\\t$5,790,678\\t11.54 cents\\n',\n",
              " '1890\\t62,979,766\\t$11,547,127\\t18.33 cents\\n',\n",
              " '1900\\t76,303,387\\t$11,854,000\\t15.54 cents\\n',\n",
              " '1910\\t91,972,266\\t$15,968,000\\t17.07 cents\\n',\n",
              " '1920\\t105,710,620\\t$25,117,000\\t23.76 cents\\n',\n",
              " '1930\\t122,775,046\\t$40,156,000\\t32.71 cents\\n',\n",
              " '1940\\t131,669,275\\t$67,527,000\\t51.29 cents\\n',\n",
              " '1950\\t151,325,798\\t$91,462,000\\t60.44 cents\\n',\n",
              " '1960\\t179,323,175\\t$127,934,000\\t71.34 cents\\n',\n",
              " '1970\\t203,302,031\\t$247,653,000\\t$1.22\\n',\n",
              " '1980\\t226,542,199\\t$1,078,488,000\\t$4.76\\n',\n",
              " '1990\\t248,718,301\\t$2,492,830,000\\t$10.02\\n',\n",
              " '2000\\t281,421,906\\t$4.5 Billion\\t$15.99\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW1Erv2uHRdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d9c8b99e-7f2f-43a0-9ec6-fa75b0677e08"
      },
      "source": [
        "# Extract the column \"Census Year\" from data_list and assign them to a list named year_list. Remove the \"\" from the last element \"2010\". Print the cleansed year_list.\n",
        "year_list = data_list[1::]\n",
        "print(year_list)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['1820\\t9,633,822\\t$208,526\\t2.16 cents\\n', '1830\\t12,866,020\\t$378,545\\t2.94 cents\\n', '1840\\t17,069,458\\t$833,371\\t4.88 cents\\n', '1850\\t23,191,876\\t$1,423,351\\t6.14 cents\\n', '1860\\t31,443,321\\t$1,969,377\\t6.26 cents\\n', '1870\\t38,558,371\\t$3,421,198\\t8.87 cents\\n', '1880\\t50,155,783\\t$5,790,678\\t11.54 cents\\n', '1890\\t62,979,766\\t$11,547,127\\t18.33 cents\\n', '1900\\t76,303,387\\t$11,854,000\\t15.54 cents\\n', '1910\\t91,972,266\\t$15,968,000\\t17.07 cents\\n', '1920\\t105,710,620\\t$25,117,000\\t23.76 cents\\n', '1930\\t122,775,046\\t$40,156,000\\t32.71 cents\\n', '1940\\t131,669,275\\t$67,527,000\\t51.29 cents\\n', '1950\\t151,325,798\\t$91,462,000\\t60.44 cents\\n', '1960\\t179,323,175\\t$127,934,000\\t71.34 cents\\n', '1970\\t203,302,031\\t$247,653,000\\t$1.22\\n', '1980\\t226,542,199\\t$1,078,488,000\\t$4.76\\n', '1990\\t248,718,301\\t$2,492,830,000\\t$10.02\\n', '2000\\t281,421,906\\t$4.5 Billion\\t$15.99\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LU_SFWXEIhtD",
        "colab_type": "text"
      },
      "source": [
        "# Second Half\n",
        "- Extract the \"Census Cost\" column from the data_list and assign them to a list named \"cost_list\". Remove the \",\", and \"$\", and \"Billion\". Make sure to add the \"0\"s to the numbers from which you removed \"Billion\". Print the cleansed cost_list.  \n",
        "\n",
        "- Extract the \"Average Cost per Person\" column from the data_list and assign them to a list named \"avg_list\". Remove the \"cents\", and \"$\". Make sure to divide the numbers in cents by 100 so that all numbers are measured in dollar. Print the cleansed avg_list.  \n",
        "\n",
        "- Coalesce the cleansed data and save them to a text file named \"census_cost.csv\". The new file should look similar to the original source file except that it is in comma-delimited format and the numbers have been cleansed. The top two lines from the original file should be retained in the new file.  \n",
        "\n",
        "Give yourself a pat on the back. Good job!\n",
        "Now you know what data scientists do most of time: Data Cleansing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QbIQiBVH8wu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remake it as censuscost.txt\n",
        "census_cost.txt = "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CDmSljAFLJF",
        "colab_type": "text"
      },
      "source": [
        "# End"
      ]
    }
  ]
}